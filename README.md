## Deep-Learning-from-Scratch-3

<details>
<summary>step01</summary>

---
## 1.1 변수란 
- 상자와 데이터는 별개
- 상자에 데이터가 들어감(할당)
- 상자 속을 보면 데이터를 알 수 있음(참조)

## 1.2 Variable 클래스 구현
- Variable 클래스 선언 
- 클래스로 인스턴스를 만듬. 인스턴스는 데이터를 담은 상자가 됨

## 1.3 [보충] 넘파이의 다차원 배열
- 0차원 배열(0차원 텐서) : 스칼라(scalar)
- 1차원 배열(1차원 텐서) : 벡터(vector) -> 축이 1개
- 2차원 배열(2차원 텐서)  : 행렬(matrix) -> 축이 2개
- 다차원 배열 : 텐서(tensor)
- 3차원 벡터와 3차원 배열은 다른 의
---

</details>

<details>
<summary>step02</summary>

---
## 2.1 힘수란 
- 어떤 변수로부터 다른 변수로의 대응 관계를 정한 것 (x -> *f* -> y)

## 2.2 Function 클래스 구현
- Variable 인스턴스를 다룰 수 있는 함수를 Function 클래스로 구현  
    - Function 클래스는 Variable 인스턴스를 입력받아 Variable 인스턴스를 출력함
    - Variable 인스턴스의 실제 데이터는 인스턴스 변수인 data에 있음

## 2.3 Function 클래스의 이용 
- DeZero 함수의 충족 사항   
    - Function 클래스는 기반 클래스로서, 모든 함수에 공통되는 기능을 구현한다.
    - 구체적인 함수는 Function 클래스를 상속한 클래스에서 구현한다.
- Note : Function 클래스의 forward 메서드는 예외를 발생시킨다. 이렇게 해두면 Function 클래스의 forward 메서드를 직접 호출한 사람에게 '이 메서드는  상속하여 구현해야 한다.' 는 사실을 알려줄 수 있다
---

</details>

<details>
<summary>step03</summary>

---
## 3.1 Exp 함수 구현 
- $y=e^x$ 구현. $e$는 자연로그의 밑, 2.718..., 오일러의 수, 네이피어 상수

## 3.2 함수 연결
- Function 클래스의 __call__ 메서드의 입,출력이 모두 Variable 인스턴스이기 때문에 함수 연결이 가능함
- $y=(e^{x^2})^2$ 계산도 가능
- 어려 함수로 구성된 함수를 **합성 합수** 라고 함
- 일련의 계산으로 계산 그래프로 그림 이유는? 
    - 계산 그래프를 이용하면 각 변수에 대한 미분을 효율적으로 계산할 수 있기 떄문임
    - 변수별 미분을 계산하는 알고리즘이 바로 **역전파**
---

</details>

<details>
<summary>step04</summary>

---
## 4.1 미분이란 
- 미분은 변화율 
    - 물체의 시간에 따른 위치 변화율(위치의 미분)은 속도
    - 시간에 대한 속도 변화율(속도의 미분)은 가속도 
- 정의는 '극한으로 가는 짧은 시간(순간)'에서의 변화량 
$$f'(x)=\displaystyle\lim_{h{\rightarrow}0}{\frac{f(x+h)-f(x)}{h}}$$
- $y=f(x)$가 어떤 구간에서 미분이 가능하다면 $f'(x)$ 도 함수이며, $f(x)$의 도함수라고 함

## 4.2 수치 미분 구현
- 컴퓨터는 극한을 취급할 수 없으니 극한과 비슷한 값으로 대체 
- $h=0.0001(=1e-4)$ 와 같은 매우 작은 값을 이용하여 함수의 변화량을 구하는 방법을 **수치미분**(numerical differentiation)이라고 함
- 수치 미분은 작은 값을 사용하여 '진정한 미분'을 근사함, 따라서 어쩔 수 없이 오차가 포함됨
- 이 오차를 줄이는 방법으로 '중앙차분', $f(x)$와 $f(x+h)$의 차이를 구하는 대신 $f(x-h)$와 $f(x+h)$의 차이를 구함

## 4.3 합성 함수의 미분
- 합성함수 $y=(e^{x^2})^2$ 의 미분
- 미분한 값이 3.297... 이라면, x를 0.5에서 작은 값만큼 변화시키면 y는 작은 값의 3.297...배만큼 변한다는 의미
- 복잡한 함수라도 원하는 함수를 선언한 후 미분 가능, 그러나 수치 미분의 문제가 있음

## 4.4 수치 미분의 문제점
- 수치 미분의 결과에는 오차가 포함되어있음 대부분의 경우 매우 작지만 어떤 계산이냐에 따라 커질 수도 있음
    - 오차가 포함되기 쉬운 이유는 주로 '자릿수 누락'
    - 차이를 구하는 계산은 주로 크기가 비슷한 값들을 다루므로 자릿수 누락이 생겨 유효 자릿수가 줄어들 수 있음
- 더 심각한 문제는 계산량이 많다는 점, 변수가 여러 개인 계산을 미분할 경우 변수 각각을 미분해야하기 떄문
- 신경망에서는 매개변수를 수백만 개 이상 사용하는 것은 일도 아님, 그래서 등장한 것이 **역전파**
- 수치 미분은 구현이 쉽고 거의 정확한 값을 얻을 수 있음, 이에 비해 역전파는 복잡한 알고리즘이라서 버그가 섞여 들어가기 쉬움
- 정확히 구현했는지 확인을 위해 수치미분 결과를 이용, 이를 **기울기 확인**(gradient checking)
---

</details>

<details>
<summary>step05</summary>

---
## 5.1 연쇄 법칙
- 역전파(backpropagation, 오차역전파법)를 이해하는 열쇠는 **연쇄 법칙**(chain rule)
- 연쇄 법칙에 따르면 합성 함수(여러함수가 연결된 함수)의 미분은 구성 함수 각각을 미분한 후 곱한 것과 같다고 함
- $a = A(x)$, $b = B(a)$, $y = C(b)$ $\Rightarrow$ $y = C(B(A(x)))$
$$\frac{dy}{dx} = \frac{dy}{db}\frac{db}{da}\frac{da}{dx}$$
$$\frac{dy}{dx} = \frac{dy}{dy}\frac{dy}{db}\frac{db}{da}\frac{da}{dx}$$
- $\frac{dy}{dy}$는 1

## 5.2 역전파 원리 도출
- 출력에서 입력 방향으로(즉, 역방향으로) 순서대로 계산
$$\frac{dy}{dx} = ((\frac{dy}{dy}\frac{dy}{db})\frac{db}{da})\frac{da}{dx}$$
- 미분값이 오른쪽에서 왼쪽으로 전파되는 것을 알 수 있음, 역전파 

## 5.3 계산 그래프로 살펴보기
- 순전파
$$x \rightarrow A \rightarrow a \rightarrow B \rightarrow b \rightarrow C \rightarrow y$$
- 역전파
$$\frac{dy}{dx} \leftarrow A'(x) \leftarrow \frac{dy}{da} \leftarrow B'(a) \leftarrow \frac{dy}{db} \leftarrow C'(b) \leftarrow \frac{dy}{dy}$$
- 위의 식을 잘 보면 역전파 시에는 순전파 시 이용한 데이터가 필요하다는 것을 알 수 있음 
- 따라서, 역전파를 구하려면 먼저 순전파를 하고 각 합수의 입력변수(x, a, b)의 값을 꼭 기억해둬야함 
---

</details>

<details>
<summary>step06</summary>

---
## 6.1 Variable 클래스 추가 구현
- 미분값도 저장하도록 확장

## 6.2 Function 클래스 추가 구현
- 미분을 계산하는 역전파(backward 메서드) 추가
- forward 메서드 호출 시 건네받은 Variable 인스턴스 유지 추가

## 6.3 Square 과 Exp 클래스 추가 구현
- $y=x^2$, $y=e^x$ 의 각 미분값을 곱해주는 함수 추가

## 6.4 역전파 구현
- 역전파는 $\frac{dy}{dy}=1$ 에서 시작, 출력 y의 미분값을 np.array(1.0)



---

</details>

